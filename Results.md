## Results and Analysis

#### Performance

* MCQ (227 / 227 / 418)
    - left: direct evaluation
    - right: circular evaluation

|            Models            |        CI (low)     |       CI (high)     |       SI (high)     |
|            :-                |          :-:        |         :-:         |         :-:         |
|       mPLUG-Owl2             |    34.80 / 21.14    |    25.99 / 13.22    |    67.70 / 50.72    |
|       mPLUG-Owl2 (+ VC)      |    39.21 / 22.47    |    26.87 / 14.10    |    66.27 / 51.44    |
| | | | |
|       deepseek_vl_7b         |    47.58 / 36.12    |    36.56 / 25.99    |    74.40 / 59.33    |
|       deepseek_vl_7b (+ VC)  |    50.22 / 37.00    |    38.77 / 31.28    |    75.60 / 58.85    |
| | | | |
|       llava_v1.5_7b          |    39.21 / 20.26    |    26.87 / 14.10    |    71.29 / 57.18    |
|       llava_v1.5_7b (+ VC)   |    40.09 / 17.62    |    26.43 / 18.06    |    72.25 / 55.74    |
| | | | |
|       llava_v1.5_13b         |    41.85 / 25.99    |    32.60 / 18.06    |    72.25 / 55.02    |
|       llava_v1.5_13b (+ VC)  |    45.37 / 24.23    |    33.92 / 12.78    |    73.44 / 57.18    |
| | | | |
|       GPT4V                  |    63.00 / 44.50    |    37.44 / 14.10    |    72.25 / 59.81    |
|       GPT4V (+ VC)           |    63.44 / 48.02    |    34.36 / 19.82    |    72.97 / 61.24    |
| | | | |
|       GPT4o                  | **87.22** / 74.01   |  **51.54** / 34.80  |    77.27 / 64.83    |
|       GPT4o (+ VC)           |  86.34 / **78.41**  |**51.54** / **43.17**|**77.51** / **65.79**|

* Yes or No (270 / 270 / 230 / 230 // 270 / 230 // 169 / 169 // 169)
    - S/E: source/edited image
    - qAcc: for each question, whether the model answer correctly on both images
    - iAcc: for each image, whether the model answer all questions correctly
    - aAcc: accuracy on 1000 questions
    - mAcc: for each pair of image, whether the model answer all questions correctly on both images

|         Models      | S (low) | E (low) | S (high) | E (high) | qAcc (low) | qAcc (high) | iAcc (S) | iAcc (E) |  aAcc  |   mAcc   |
|         :-          |  :-:    |    :-:  |  :-:     |    :-:   |  :-:       |   :-:       |  :-:     |   :-:    |  :-:   |   :-:   |
|    mPLUG-Owl2       | 87.41   | 81.85   |  80.43   |  72.17   |   69.26    |   54.78     |  66.27   |  54.44   |  80.8  |  36.09  |
|    deepseek_vl_7b   | 86.67   |  82.96  |  83.04   |  69.13   |   70.00    |   54.35     |  68.05   |  52.07   |  80.8  |  33.73  |
| | | | | | | | | | | |
|    instruct_blip_7b      | 77.04 | 72.59   | 66.96 |  71.30   | 49.63  | 40.00   | 44.38 |  44.97   | 72.20 |  17.75  |
|    instruct_blip_13b     | 76.30 | 74.07   | 63.91 |  71.30   | 50.37  | 36.09   | 41.42 |  46.15   | 71.7 |  15.98  |
| | | | | | | | | | | |
|    llava_v1.5_7b    | 86.30   | 82.59   |  79.57   |  71.30   |   68.89    |   51.74     |  64.50   |  52.66   |  80.3  |  31.36  |
|    llava_v1.5_13b   | 85.56   | 81.11   |  76.09   |**76.09** |   66.67    |   52.17     |  58.58   |  55.62   |  80.0  |  28.40  |
| | | | | | | | | | | |
|    GPT4V            | 88.89   | 75.56   |  86.52   |  51.74   |   66.30    |   39.57     |  71.01   |  30.77   |  76.2  |  23.08  |
|    GPT4V (+ VC)     | 90.37   | 74.07   |**87.39** |  55.22   |   64.81    |   43.91     |  75.15   |  37.28   |  77.2  |  30.77  |
| | | | | | | | | | | |
|    GPT4o            |  92.96  | 80.74   |  86.52   |  65.65   |   74.44    |   56.09     |  76.92   |  48.52   |  81.9  |**39.05**|
|    GPT4o (+ VC)     |**93.33**| 81.85   |**87.39** |  68.70   | **75.19**  | **58.70**   |**78.11** |  49.70   |**83.2**|  38.46  |
| | | | | | | | | | | |